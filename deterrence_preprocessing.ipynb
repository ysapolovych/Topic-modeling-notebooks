{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "200713 deterrence preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Preliminary data formatting](https://colab.research.google.com/drive/1MMwTOOgMKuZMWnsl9vxWUB6reXAZJndc?usp=sharing) was done before loading the data to this notebook."
      ],
      "metadata": {
        "id": "yRlWSmYySXQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import\n",
        "\n",
        "We start by importing the necessary libraries (and their dependent requirements) that we will need further down the pipeline to process everything."
      ],
      "metadata": {
        "id": "lLGdrYKERE3w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "! pip install pymorphy2==0.8 git+https://github.com/buriy/spacy-ru@v2.1 #spacy==2.1.9"
      ],
      "outputs": [],
      "metadata": {
        "id": "1EBNIuZUb0dY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "daae07a7-0429-49ad-ea7d-c01260b3eb5e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "! git clone --branch v2.1 https://github.com/buriy/spacy-ru"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'spacy-ru'...\n",
            "remote: Enumerating objects: 118, done.\u001b[K\n",
            "remote: Counting objects: 100% (118/118), done.\u001b[K\n",
            "remote: Compressing objects: 100% (90/90), done.\u001b[K\n",
            "remote: Total 511 (delta 45), reused 83 (delta 25), pack-reused 393\u001b[K\n",
            "Receiving objects: 100% (511/511), 180.76 MiB | 12.64 MiB/s, done.\n",
            "Resolving deltas: 100% (215/215), done.\n"
          ]
        }
      ],
      "metadata": {
        "id": "Xan60GxCb-Bi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "fd5f3014-1116-4dee-c80f-7db0211d1b63"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# nltk will be used for tokenization and stopwords removal\r\n",
        "import pandas as pd # for dataframes\r\n",
        "import re # for operations with regex\r\n",
        "# import numpy as np # for numeric operations\r\n",
        "# import os #for misc system-related funcs\r\n",
        "from pathlib import Path # for operations with path\r\n",
        "from itertools import chain\r\n",
        "from joblib import Parallel, delayed\r\n",
        "\r\n",
        "#spacy + pymorphy2 for Russian lemmatization\r\n",
        "import spacy \r\n",
        "import pymorphy2\r\n",
        "\r\n",
        "# gensim phrases for ngrams extraction\r\n",
        "from gensim.models.phrases import Phrases"
      ],
      "outputs": [],
      "metadata": {
        "id": "HqYXrYmXiiwL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data\r\n",
        "We now have to get the actual text documents into a dataframe that our notebook will be able to work with. You can think of a dataframe as a table in which \r\n",
        "*   each ***row*** represents one text document, and in which  \r\n",
        "*   each ***column*** contains a field such as the full text of the document itself, but also a set of metadata like the document's date of publication, its author, its source, etc. \r\n",
        "\r\n",
        "These documents have been packaged into a json file."
      ],
      "metadata": {
        "id": "bD4IAUMFUciC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "data = pd.read_json('/Corpora/Deterrence/200708_ru_deter_full.json', \r\n",
        "                    convert_dates = False)\r\n",
        "\r\n",
        "data.drop(columns=['date'], inplace = True)\r\n",
        "\r\n",
        "data.rename(columns={'date_rough':'date'}, inplace = True)\r\n",
        "\r\n",
        "data[\"date\"] = pd.to_datetime(data[\"date\"], format='%Y-%m-%d %H:%M:%S', errors = 'coerce')"
      ],
      "outputs": [],
      "metadata": {
        "id": "Lxx16oU_X5lq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Corpus stats"
      ],
      "metadata": {
        "id": "f2si2oMW1TjL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# let's take a look at the time span\r\n",
        "print(f'{sum(data[\"date\"].isna())} objects have no date assigned')\r\n",
        "print(f'Earliest date in the corpus: {data[\"date\"].min()}')\r\n",
        "print(f'Latest date in the corpus: {data[\"date\"].max()}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 objects have no date assigned\n",
            "Earliest date in the corpus: 1961-01-01 00:00:00+00:00\n",
            "Latest date in the corpus: 2020-01-01 00:00:00+00:00\n"
          ]
        }
      ],
      "metadata": {
        "id": "_CMrSK7ug4g1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "1a076a8a-85dd-4e3b-cd60-de2ce5cbfb1e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#let's now calculate min, avg, max of len and stdv\r\n",
        "# first we create a function to generate lengths of each text\r\n",
        "import statistics\r\n",
        "text_lengths = []\r\n",
        "for i in data['fulltext']:\r\n",
        "  text_lengths.append(len(i))"
      ],
      "outputs": [],
      "metadata": {
        "id": "M1qVaM6L4nos"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#now let's see how big our texts are\r\n",
        "print(f'max text length: {max(text_lengths)}')\r\n",
        "print(f'min text length: {min(text_lengths)}')\r\n",
        "print(f'mean: {round(statistics.mean(text_lengths))} and median:{statistics.median(text_lengths)}')\r\n",
        "print(f'standard deviation of text length: {round(statistics.stdev(text_lengths))}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max text length: 2341051\n",
            "min text length: 103\n",
            "mean: 29116 and median:15407.0\n",
            "standard deviation of text length: 78162\n"
          ]
        }
      ],
      "metadata": {
        "id": "UaYO0GBW5_w8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "e424f4ee-15f0-4078-c558-f3b139d3de62"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#let's find out docs distribution over time\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "docs_time = data.groupby(pd.Grouper(key='date', freq='Y')).fulltext.agg('count')\r\n",
        "docs_time.plot.line(y = 'count')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4929f67be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ],
      "metadata": {
        "id": "heq17gBPZDkS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "e1e4aa5a-0a58-4445-ac69-80599bdb3078"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing\n",
        "Now that we have everything loaded, we can start processing the documents.\n"
      ],
      "metadata": {
        "id": "22ULM_DgxjeY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Context window extraction #1"
      ],
      "metadata": {
        "id": "99t2fntLME5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Many of our documents are quite sizeable, and may contain many paragraphs that are not at all relevant to the issue we our interested in (deterrence). This section extracts 'context windows' for excerpts that are relevant for deterrence. You'll find the more detailed documentation [here](https://rizzoma.com/topic/4ccb0b922026dc65818727aaecf5553c/0_b_ajoa_agl7a/)"
      ],
      "metadata": {
        "id": "M3lSwkq_fmGH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "pattern = r'устраш|сдерж|запуг' #define patterns it will filter by\r\n",
        "negative_pattern = r'сдержанн' #this word is a sure indicator a text is irrelevant\r\n",
        "\r\n",
        "print(f'Before extracting paragraphs: {len(data.index)}')\r\n",
        "\r\n",
        "data = data[data['fulltext'].str.contains(pattern, case = False, regex = True)]\r\n",
        "\r\n",
        "data = data[~data['fulltext'].str.contains(negative_pattern, case = False, regex = True)]\r\n",
        "\r\n",
        "print(f'After extracting relevant paragraphs: {len(data.index)}')\r\n",
        "# print an example paragraph"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before extracting paragraphs: 5534\n",
            "After extracting relevant paragraphs: 4118\n"
          ]
        }
      ],
      "metadata": {
        "id": "H3ipsfVt0G-P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e2c1df09-dc4b-4dcc-ee39-ea1775703859"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#let's drop NAs and empty strings (given there are any)\r\n",
        "print(f'Before dropping NAs: {len(data.index)}')\r\n",
        "\r\n",
        "data.dropna(subset = ['fulltext'], inplace = True)\r\n",
        "\r\n",
        "data = data[data['fulltext']!='']\r\n",
        "\r\n",
        "data = data[data['fulltext'].str.len()>10]\r\n",
        "\r\n",
        "data.reset_index(inplace = True, drop = True)\r\n",
        "\r\n",
        "print(f'After dropping NAs: {len(data.index)}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before dropping NAs: 4118\n",
            "After dropping NAs: 4118\n"
          ]
        }
      ],
      "metadata": {
        "id": "1PG8zyHw7ZRU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6c2c41fd-05c7-452f-e7d2-a79e34340088"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization into paragraphs\r\n",
        "When humans write texts, they break it up in smaller chunks like sentences of paragraphs. In this pre-processing step, we first split the documents into 'paragraphs' first. Paragraphs in this case are defined as either periods or exclamation/question marks followed by a newline character. \r\n",
        "\r\n",
        "This approach, while arguably quite brutish, works pretty well.\r\n"
      ],
      "metadata": {
        "id": "2vMyWUBnm49x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "paragraph_delim = re.compile(r'!\\s*\\n|\\.+\\s*\\n|\\?\\s*\\n') # define a pattern for paragraph delimiter\r\n",
        "\r\n",
        "# apply tokenization into paragraphs;\r\n",
        "# after applying, each text cell should be a list with paragraph per element\r\n",
        "data['fulltext'] = data['fulltext'].apply(lambda a: re.split(paragraph_delim, a)) \r\n",
        "\r\n",
        "data = data.explode('fulltext') # now let's create a new row from each list element\r\n",
        "\r\n",
        "data.reset_index(inplace = True, drop = True) # and reset index of rows"
      ],
      "outputs": [],
      "metadata": {
        "id": "kVneB-hrnSYd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization into sentences and words"
      ],
      "metadata": {
        "id": "sSySRUZNWXrd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# initialize nlp object\r\n",
        "nlp = spacy.load('/content/spacy-ru/ru2', disable = ['parser', 'ner'])\r\n",
        "nlp.add_pipe(nlp.create_pipe('sentencizer'), first=True)\r\n",
        "nlp.max_length = 300000"
      ],
      "outputs": [],
      "metadata": {
        "id": "hu8rGxPcWa5N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check out [this post](https://towardsdatascience.com/turbo-charge-your-spacy-nlp-pipeline-551435b664ad) for the source of the most code below. Also tried out different approaches to boosting spaCy [here](https://colab.research.google.com/drive/17H2RJsbqbqpw1HR-DhctHIuv3vNplR12?usp=sharing), this one was far the most successful."
      ],
      "metadata": {
        "id": "L_4M1Vi_Qw6A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def chunker(iterable, total_length, chunksize):\r\n",
        "    #\"returns a generator that only contains that particular chunk's text as a list of strings\"\r\n",
        "    return (iterable[pos: pos + chunksize] for pos in range(0, total_length, chunksize))\r\n",
        "\r\n",
        "def process_chunk(texts, pattern = re.compile(r'[a-z|а-я]+')):\r\n",
        "    #processes the texts with an nlp object\r\n",
        "    preproc_pipe = []\r\n",
        "    for doc in nlp.pipe(texts, batch_size=20):\r\n",
        "        processed_doc = [[token.lemma_ for token in sentence if re.match(pattern, token.lemma_)] for sentence in doc.sents]\r\n",
        "        preproc_pipe.append(processed_doc)\r\n",
        "    return preproc_pipe\r\n",
        "\r\n",
        "def flatten(list_of_lists):\r\n",
        "    #\"flatten a list of lists to a combined list\"\r\n",
        "    return [item for sublist in list_of_lists for item in sublist]\r\n",
        "\r\n",
        "def preprocess_parallel(texts, chunksize=100):\r\n",
        "    #apply all of the above to process texts in parallel\r\n",
        "    executor = Parallel(n_jobs=2, backend='multiprocessing', prefer=\"processes\")\r\n",
        "    do = delayed(process_chunk)\r\n",
        "    tasks = (do(chunk) for chunk in chunker(texts, len(data), chunksize=chunksize))\r\n",
        "    result = executor(tasks)\r\n",
        "    return flatten(result)"
      ],
      "outputs": [],
      "metadata": {
        "id": "C7iX0Ux0Nim8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%time\r\n",
        "\r\n",
        "data['processed_text'] = preprocess_parallel(data['fulltext'], chunksize = 100)\r\n",
        "# df_preproc[['date', 'content', 'preproc_pipe']].head(3)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 13.1 s, sys: 3.18 s, total: 16.3 s\n",
            "Wall time: 11min 34s\n"
          ]
        }
      ],
      "metadata": {
        "id": "13Ji70o0N9JZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2f3b85f7-7619-4ed9-891a-7b8f17d78f92"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## N-grams"
      ],
      "metadata": {
        "id": "eTaKAzkwNepy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gensim Ngrams require the training data to be tokenized into sentences. We'll create a separate variable with sentencized texts for ngrams."
      ],
      "metadata": {
        "id": "pw8HARYLOyHS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "data['processed_text'].isna().sum()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ],
      "metadata": {
        "id": "xjrUEArzDw4J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2375c7e5-0b1f-4c5a-dfcb-8c365819f78f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "sentences = data['processed_text'].explode().dropna().tolist()"
      ],
      "outputs": [],
      "metadata": {
        "id": "n9NIpgMieDNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we'll define the normalization func (tokenization and lemmatization) that we'll use later"
      ],
      "metadata": {
        "id": "S3-_d9WrpR5j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%time\r\n",
        "bigram = Phrases(sentences[0:876240], min_count=6, \r\n",
        "                 threshold=25, #we'd still need to experiment with these two params\r\n",
        "                 delimiter=b'_')\r\n",
        "trigram = Phrases(bigram[sentences], min_count=6, threshold=15, \r\n",
        "                  delimiter=b'_') # add one word to already generated bigrams where possible"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 57s, sys: 1.16 s, total: 1min 58s\n",
            "Wall time: 1min 58s\n"
          ]
        }
      ],
      "metadata": {
        "id": "ZXK6_LpBRkY_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "8bb9ff4b-23e7-4b5d-b1f3-5245b852be04"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#let's see an instance of these\r\n",
        "print(trigram[bigram[sentences]][4])\r\n",
        "\r\n",
        "sentences = ''"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['джон_кеннеди', 'и', 'никита_хрущев', 'в', 'отличие_от', 'фидель_кастро', 'действительно', 'не', 'намного', 'пережить', 'событие', 'карибский_кризис']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ]
        }
      ],
      "metadata": {
        "id": "22FwG9mF16Te",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "2a9dab97-fcbf-43d5-b6b4-e0770b5fb826"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will apply ngrams\n",
        "\n"
      ],
      "metadata": {
        "id": "6JF3glCloFVa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%time\r\n",
        "data.columns"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 7 µs, sys: 0 ns, total: 7 µs\n",
            "Wall time: 9.78 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['author', 'database', 'doi', 'filename', 'fulltext', 'place',\n",
              "       'pubtitle', 'title', 'url', 'date', 'source_site', 'Pubtype',\n",
              "       'Author name', 'Title', 'Publication type (civ/mil)',\n",
              "       'Author background (civ/mil)', 'Gender', 'processed_text'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ],
      "metadata": {
        "id": "JtqUfrInGX7u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "7a0b9095-b1ca-46f9-accb-05dbef3b8b83"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# now to underscore all phrases in the texts data['preprocessed_texts']\r\n",
        "data['processed_text'] = data['processed_text'].apply(lambda paragraph: [trigram[bigram[sentence]] for sentence in paragraph]) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ]
        }
      ],
      "metadata": {
        "id": "iKL9YSEPqqzx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "9f5d2a74-9ae2-4717-e977-3833dcee6ab1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# let's flatten our paragraphs: we don't need sentence boundaries anymore\r\n",
        "# data['processed_text'] = data['processed_text'].apply(lambda l: list(chain(*l)))\r\n",
        "print(data['processed_text'][0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['карибский_кризис', 'два', 'проиграть', 'и', 'один', 'победитель', 'максим', 'кузахметов', 'парадоксальный_образ', 'главный', 'победитель', 'по', 'итог', 'карибский_кризис', 'стать', 'человек', 'чей', 'действие', 'во_многом', 'и', 'спровоцировали', 'драматический', 'противостояние', 'ссср', 'и', 'сша', 'в', 'октябрь_год']\n"
          ]
        }
      ],
      "metadata": {
        "id": "wmouvfSMHwZe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7185621b-ff46-407e-e675-785a45a508ac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove stopwords\n",
        "A tricky part here is leaving only meaningful ngrams, which are all *but*:\n",
        "\n",
        "*   bigrams with one or two stopwords, e.g. \"тот_кто\" or \"с_министром\";\n",
        "*   trigrams with either 3 stopwords or stopwords in the ending/beginning: \"когда_президент_с\".\n",
        "\n",
        "Below will be the main function which will check if an ngram passess these requirements. If not - it will either reduce it or completely disintegrate. The function is super clumsy but I couldn't come up with anything better so far.\n",
        "\n"
      ],
      "metadata": {
        "id": "NGY2AMv1fZ8j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# download NLTK stopwords\r\n",
        "! wget https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/stopwords.zip && unzip stopwords.zip"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2020-07-14 11:41:28--  https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/stopwords.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23047 (23K) [application/zip]\n",
            "Saving to: ‘stopwords.zip’\n",
            "\n",
            "\rstopwords.zip         0%[                    ]       0  --.-KB/s               \rstopwords.zip       100%[===================>]  22.51K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2020-07-14 11:41:28 (2.24 MB/s) - ‘stopwords.zip’ saved [23047/23047]\n",
            "\n",
            "Archive:  stopwords.zip\n",
            "   creating: stopwords/\n",
            "  inflating: stopwords/dutch         \n",
            "  inflating: stopwords/german        \n",
            "  inflating: stopwords/slovene       \n",
            "  inflating: stopwords/hungarian     \n",
            "  inflating: stopwords/romanian      \n",
            "  inflating: stopwords/kazakh        \n",
            "  inflating: stopwords/turkish       \n",
            "  inflating: stopwords/russian       \n",
            "  inflating: stopwords/README        \n",
            "  inflating: stopwords/italian       \n",
            "  inflating: stopwords/english       \n",
            "  inflating: stopwords/greek         \n",
            "  inflating: stopwords/tajik         \n",
            "  inflating: stopwords/norwegian     \n",
            "  inflating: stopwords/portuguese    \n",
            "  inflating: stopwords/finnish       \n",
            "  inflating: stopwords/danish        \n",
            "  inflating: stopwords/french        \n",
            "  inflating: stopwords/swedish       \n",
            "  inflating: stopwords/azerbaijani   \n",
            "  inflating: stopwords/spanish       \n",
            "  inflating: stopwords/indonesian    \n",
            "  inflating: stopwords/arabic        \n",
            "  inflating: stopwords/nepali        \n"
          ]
        }
      ],
      "metadata": {
        "id": "_Jbkp-RdAzFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "outputId": "ae079276-1ea9-430a-d13d-66530d6c59f7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# load and extend the list of stopwords\r\n",
        "with open('/content/stopwords/russian', 'r') as infile:\r\n",
        "  stopwords = infile.read().splitlines()\r\n",
        "\r\n",
        "stopwords.extend(['the', 'url', 'com', 'www', 'html', 'and', 'of', 'for', 'news', 'http', 'org', 'метр', \r\n",
        "                        'foreign', 'financial', 'in', 'iss', 'irs', 'n', 'ст', 'index', 'php', 'rp', 'page', 'http', 'этот', \r\n",
        "                        'один', 'x', 'чем', \"также\", \"это\", \"который\", \"являться\", \"весь\", \"весь\", \"год\", \"весь\", \"год\", \r\n",
        "                        \"являться\", \"ещё\", \"еще\", 'net', 'ru', 'a', 'b', 'e', 'ad', 'f'])\r\n",
        "print(stopwords)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между', 'the', 'url', 'com', 'www', 'html', 'and', 'of', 'for', 'news', 'http', 'org', 'метр', 'foreign', 'financial', 'in', 'iss', 'irs', 'n', 'ст', 'index', 'php', 'rp', 'page', 'http', 'этот', 'один', 'x', 'чем', 'также', 'это', 'который', 'являться', 'весь', 'весь', 'год', 'весь', 'год', 'являться', 'ещё', 'еще', 'net', 'ru', 'a', 'b', 'e', 'ad', 'f']\n"
          ]
        }
      ],
      "metadata": {
        "id": "C46J8OVkBa5R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6d7ec6e3-8e0d-4ae4-b5c2-a719e2a954e7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can build a function to clean the text from stopwords."
      ],
      "metadata": {
        "id": "rvt1tasiMXdI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def clean_ngram(text, stopwords = stopwords):\r\n",
        "  new_text = []\r\n",
        "  for token in text:\r\n",
        "    if type(token) is str:\r\n",
        "      if '_' in token:\r\n",
        "        ngram = token.split('_')\r\n",
        "        if len(ngram) >= 3:\r\n",
        "          ngram = [word for ind, word in enumerate(ngram) if word not in stopwords or ind == 1]\r\n",
        "        elif len(ngram) == 2:\r\n",
        "          ngram = [word for word in ngram if word not in stopwords]\r\n",
        "        elif len(ngram) == 0:\r\n",
        "          ngram = None      \r\n",
        "        \r\n",
        "        if len(ngram) == 1:\r\n",
        "          ngram = ngram[0]\r\n",
        "        elif len(ngram) > 1:\r\n",
        "          ngram = ' '.join(ngram)\r\n",
        "      \r\n",
        "      elif token == '' or token in stopwords:\r\n",
        "        ngram = None\r\n",
        "      else:\r\n",
        "        ngram = token\r\n",
        "    else:\r\n",
        "      ngram = None\r\n",
        "    new_text.append(ngram)\r\n",
        "  \r\n",
        "  new_text = [token for token in new_text if token] \r\n",
        "  return new_text "
      ],
      "outputs": [],
      "metadata": {
        "id": "ZGqA8E6uJA4-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "data['processed_text'] = data['processed_text'].apply(clean_ngram)\r\n",
        "data['processed_text'][10]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['время',\n",
              " 'кризис',\n",
              " 'день',\n",
              " 'самой',\n",
              " 'острый фаза',\n",
              " 'кризис',\n",
              " 'хрущев',\n",
              " 'дать',\n",
              " 'разрешение',\n",
              " 'применение ядерный оружие',\n",
              " 'против',\n",
              " 'сша',\n",
              " 'союзник',\n",
              " 'проявить',\n",
              " 'инициатива',\n",
              " 'поиск',\n",
              " 'мирный путь',\n",
              " 'выход',\n",
              " 'опасный',\n",
              " 'военный',\n",
              " 'противостояние',\n",
              " 'решение',\n",
              " 'вывод',\n",
              " 'советский',\n",
              " 'ракета',\n",
              " 'куба',\n",
              " 'принимать',\n",
              " 'фактически',\n",
              " 'единолично']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ],
      "metadata": {
        "id": "LeMTaOs5L3ZB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "63e45d0e-6591-42d7-f54c-2b67c50aca42"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Context window extraction #2 (for ngram analysis)\r\n",
        "Now that our corpus is lemmatized and has no stopwords, we can filter out more irrelevant paragraphs and generate the best-quality ngrams for our analysis. For this, we'll try to identify the most common meaningful terms in our golden corpus, and then filter our common corpus on them."
      ],
      "metadata": {
        "id": "cGslk3GRh_FW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#https://programminghistorian.org/en/lessons/keywords-in-context-using-n-grams\r\n",
        "\r\n",
        "def get_kwic(wordlist, n = 4, pattern = re.compile('устраш.*|сдерж.*')):\r\n",
        "    # kwic = [wordlist[i:i+n] for i in range(len(wordlist)-(n-1))]\r\n",
        "    kwic = []\r\n",
        "    index = [ind for ind, word in enumerate(wordlist) if re.match(pattern, word)]\r\n",
        "    for i in index:\r\n",
        "      keywd = (wordlist[(i-n):(i+n)])\r\n",
        "      kwic.append(keywd)\r\n",
        "    return kwic"
      ],
      "outputs": [],
      "metadata": {
        "id": "qCWDXBUFgLuV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "get_kwic(data['processed_text'][2])"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['принятие решение',\n",
              "  'стать',\n",
              "  'шаг',\n",
              "  'путь',\n",
              "  'сдерживание',\n",
              "  'распространение',\n",
              "  'атомный оружие',\n",
              "  'последующий']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ],
      "metadata": {
        "id": "5s4Ls7fibGzY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "4275e7a5-fc51-404a-b880-9b0a1d3e2bae"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "keywords = data['processed_text'].apply(get_kwic).explode().dropna()\r\n",
        "pd.DataFrame(keywords.to_list())"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>принятие решение</td>\n",
              "      <td>стать</td>\n",
              "      <td>шаг</td>\n",
              "      <td>путь</td>\n",
              "      <td>сдерживание</td>\n",
              "      <td>распространение</td>\n",
              "      <td>атомный оружие</td>\n",
              "      <td>последующий</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>внешний политика</td>\n",
              "      <td>аc</td>\n",
              "      <td>www.proatom.ru</td>\n",
              "      <td>сша</td>\n",
              "      <td>сдерживание</td>\n",
              "      <td>россия</td>\n",
              "      <td>новый</td>\n",
              "      <td>американский</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>кеннан</td>\n",
              "      <td>автор</td>\n",
              "      <td>знаменитый</td>\n",
              "      <td>концепция</td>\n",
              "      <td>сдерживание containment</td>\n",
              "      <td>коммунизм</td>\n",
              "      <td>хороший</td>\n",
              "      <td>американский</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>пытаться</td>\n",
              "      <td>проводить</td>\n",
              "      <td>политика</td>\n",
              "      <td>традиционный</td>\n",
              "      <td>сдерживание</td>\n",
              "      <td>несмотря</td>\n",
              "      <td>огромный</td>\n",
              "      <td>объёму</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>страна</td>\n",
              "      <td>наш</td>\n",
              "      <td>дело</td>\n",
              "      <td>вместе</td>\n",
              "      <td>сдерживание</td>\n",
              "      <td>гонка вооружение</td>\n",
              "      <td>несёт</td>\n",
              "      <td>выгода</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7572</th>\n",
              "      <td>ситуация</td>\n",
              "      <td>применительно</td>\n",
              "      <td>стратегический</td>\n",
              "      <td>сила</td>\n",
              "      <td>сдерживание</td>\n",
              "      <td>новый</td>\n",
              "      <td>система</td>\n",
              "      <td>оружие</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7573</th>\n",
              "      <td>реализовать</td>\n",
              "      <td>свой</td>\n",
              "      <td>ударный потенциал</td>\n",
              "      <td>достаточный</td>\n",
              "      <td>сдерживание</td>\n",
              "      <td>объём</td>\n",
              "      <td>обладать</td>\n",
              "      <td>поражающий фактор</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7574</th>\n",
              "      <td>обслуживание</td>\n",
              "      <td>применение</td>\n",
              "      <td>асимметричный</td>\n",
              "      <td>система</td>\n",
              "      <td>сдерживание</td>\n",
              "      <td>штатный численность</td>\n",
              "      <td>должный</td>\n",
              "      <td>предел</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7575</th>\n",
              "      <td>корабль</td>\n",
              "      <td>достаточный</td>\n",
              "      <td>обеспечить</td>\n",
              "      <td>асимметричный</td>\n",
              "      <td>сдерживание</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7576</th>\n",
              "      <td>знать</td>\n",
              "      <td>цепь</td>\n",
              "      <td>давно</td>\n",
              "      <td>перекусить</td>\n",
              "      <td>сдерживаться</td>\n",
              "      <td>того</td>\n",
              "      <td>разорвать</td>\n",
              "      <td>разом</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7577 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     0              1  ...               6                  7\n",
              "0     принятие решение          стать  ...  атомный оружие        последующий\n",
              "1     внешний политика             аc  ...           новый       американский\n",
              "2               кеннан          автор  ...         хороший       американский\n",
              "3             пытаться      проводить  ...        огромный             объёму\n",
              "4               страна            наш  ...           несёт             выгода\n",
              "...                ...            ...  ...             ...                ...\n",
              "7572          ситуация  применительно  ...         система             оружие\n",
              "7573       реализовать           свой  ...        обладать  поражающий фактор\n",
              "7574      обслуживание     применение  ...         должный             предел\n",
              "7575           корабль    достаточный  ...            None               None\n",
              "7576             знать           цепь  ...       разорвать              разом\n",
              "\n",
              "[7577 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ],
      "metadata": {
        "id": "AtI0EqENdUB4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "2be1b897-0cf8-4855-f32e-047e2f82a5fc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def get_kwic2(wordlist, n = 2, pattern = re.compile('устраш.*|сдерж.*')):\r\n",
        "    # kwic = [wordlist[i:i+n] for i in range(len(wordlist)-(n-1))]\r\n",
        "    kwic = []\r\n",
        "    index = [ind for ind, word in enumerate(wordlist) if re.match(pattern, word)]\r\n",
        "    for i in index:\r\n",
        "      keywd = ' '.join(wordlist[(i):(i+n)])\r\n",
        "      kwic.append(keywd)\r\n",
        "      # kwic = '\\n'.join(kwic)\r\n",
        "      if len(kwic) >=1:\r\n",
        "        return kwic\r\n",
        "      else:\r\n",
        "        return None"
      ],
      "outputs": [],
      "metadata": {
        "id": "8njc243F9HPa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "deterrence_ngrams = data['processed_text'].apply(get_kwic2).explode().dropna()\r\n",
        "deterrence_ngrams"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2               сдерживание распространение\n",
              "89                       сдерживание россия\n",
              "148       сдерживание containment коммунизм\n",
              "237                    сдерживание несмотря\n",
              "307            сдерживание гонка вооружение\n",
              "                        ...                \n",
              "303012           сдерживать доход гражданин\n",
              "303095                    сдерживание новый\n",
              "303097      сдерживание штатный численность\n",
              "303123                          сдерживание\n",
              "303134                    сдерживаться того\n",
              "Name: processed_text, Length: 6485, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ],
      "metadata": {
        "id": "foR6isxU-bt4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "6e74bbab-e767-45b7-d654-d0929f1b833f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ngram_counts = pd.DataFrame(deterrence_ngrams.value_counts().reset_index(name = 'count'))\r\n",
        "ngram_counts.to_csv('Projects/ND paper/Textmining/ngram.csv')"
      ],
      "outputs": [],
      "metadata": {
        "id": "KEiQ7t5ZAO5n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "keywords.to_csv('ND paper/Textmining/kwic.csv', index = False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "-i_fb2w8fM5y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the output\r\n",
        "Further modeling and analysis will be done in a separate notebook."
      ],
      "metadata": {
        "id": "ty3uLF7k1M3I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "data.columns"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['author', 'database', 'doi', 'filename', 'fulltext', 'place',\n",
              "       'pubtitle', 'title', 'url', 'date', 'source_site', 'Pubtype',\n",
              "       'Author name', 'Title', 'Publication type (civ/mil)',\n",
              "       'Author background (civ/mil)', 'Gender', 'processed_text'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ],
      "metadata": {
        "id": "TzCyf5l2_F7Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "772d8f28-7e77-43a6-a5fd-785479a3a8dd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "data.drop(columns = ['fulltext', 'filename'], inplace = True)\r\n",
        "data.rename(columns = {'processed_text':'fulltext'}, inpalce = True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "KbGBUtyhVpFR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#save the processed corpus\r\n",
        "# !mkdir \"/content/drive/My Drive/HCSS Projects/Finnish ND paper/Topic modeling\"\r\n",
        "\r\n",
        "data.to_json('ND paper/Textmining/200713_deter_evp_preprocessed.json',\r\n",
        "                  orient = 'records', force_ascii=False, date_format = 'iso')"
      ],
      "outputs": [],
      "metadata": {
        "id": "3MQc-ovf3wU3"
      }
    }
  ]
}